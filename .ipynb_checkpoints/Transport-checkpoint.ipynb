{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "from pprint import pprint\n",
    "import scipy\n",
    "import sys\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount absent values 'ftemp': 25.138 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>temp</th>\n",
       "      <th>ftemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>casual</th>\n",
       "      <th>subscribed</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19699999999999998</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.3881</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.3881</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hour  holiday  workingday  weekday  weather_type  temp  \\\n",
       "0  2011-01-03     0        0           1        1             1  0.22   \n",
       "1  2011-01-03     1        0           1        1             1  0.20   \n",
       "2  2011-01-03     4        0           1        1             1  0.16   \n",
       "3  2011-01-03     5        0           1        1             1  0.16   \n",
       "4  2011-01-03     6        0           1        1             1  0.14   \n",
       "\n",
       "                 ftemp  humidity  wind_speed  casual  subscribed  usage  \n",
       "0  0.19699999999999998      0.44      0.3582       0          15     15  \n",
       "1               0.1667      0.44      0.4179       0           6      6  \n",
       "2               0.1364      0.47      0.3881       0           3      3  \n",
       "3               0.1364      0.47      0.2836       0           9      9  \n",
       "4                    -      0.50      0.3881       0          90     90  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Amount absent values 'ftemp': %.3f\" % (len(data[data.ftemp == '-']) / len(data) * 100), '%')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02095721286370588"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_ftemp = data[data.ftemp != '-']\n",
    "medium_diff = np.mean(known_ftemp.temp - known_ftemp.ftemp.astype(float))\n",
    "medium_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[data.ftemp == '-', 'ftemp'] = data.temp - medium_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>casual</th>\n",
       "      <th>subscribed</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>-0.003679</td>\n",
       "      <td>-0.029682</td>\n",
       "      <td>0.131916</td>\n",
       "      <td>-0.271771</td>\n",
       "      <td>0.127540</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.371302</td>\n",
       "      <td>0.098023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.000468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.247877</td>\n",
       "      <td>-0.094536</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>-0.008131</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>-0.019608</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>-0.041417</td>\n",
       "      <td>-0.005842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>0.002209</td>\n",
       "      <td>-0.247877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036898</td>\n",
       "      <td>0.057356</td>\n",
       "      <td>0.053103</td>\n",
       "      <td>0.025730</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>-0.015372</td>\n",
       "      <td>0.134013</td>\n",
       "      <td>0.010684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>-0.003679</td>\n",
       "      <td>-0.094536</td>\n",
       "      <td>0.036898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>-0.043147</td>\n",
       "      <td>0.025951</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>0.002738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_type</th>\n",
       "      <td>-0.029682</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.057356</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083150</td>\n",
       "      <td>0.417010</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>-0.015864</td>\n",
       "      <td>-0.131915</td>\n",
       "      <td>-0.040555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>0.131916</td>\n",
       "      <td>-0.008131</td>\n",
       "      <td>0.053103</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>-0.083150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032506</td>\n",
       "      <td>-0.035742</td>\n",
       "      <td>0.040763</td>\n",
       "      <td>0.332923</td>\n",
       "      <td>0.103055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>-0.271771</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>0.025730</td>\n",
       "      <td>-0.043147</td>\n",
       "      <td>0.417010</td>\n",
       "      <td>-0.032506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.282958</td>\n",
       "      <td>-0.036357</td>\n",
       "      <td>-0.268173</td>\n",
       "      <td>-0.086425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_speed</th>\n",
       "      <td>0.127540</td>\n",
       "      <td>-0.019608</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>0.025951</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>-0.035742</td>\n",
       "      <td>-0.282958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>0.080219</td>\n",
       "      <td>0.025531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casual</th>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>-0.015372</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-0.015864</td>\n",
       "      <td>0.040763</td>\n",
       "      <td>-0.036357</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065853</td>\n",
       "      <td>0.981693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subscribed</th>\n",
       "      <td>0.371302</td>\n",
       "      <td>-0.041417</td>\n",
       "      <td>0.134013</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>-0.131915</td>\n",
       "      <td>0.332923</td>\n",
       "      <td>-0.268173</td>\n",
       "      <td>0.080219</td>\n",
       "      <td>0.065853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.254705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usage</th>\n",
       "      <td>0.098023</td>\n",
       "      <td>-0.005842</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>-0.040555</td>\n",
       "      <td>0.103055</td>\n",
       "      <td>-0.086425</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.981693</td>\n",
       "      <td>0.254705</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  hour   holiday  workingday   weekday  weather_type  \\\n",
       "hour          1.000000  0.000468    0.002209 -0.003679     -0.029682   \n",
       "holiday       0.000468  1.000000   -0.247877 -0.094536     -0.013434   \n",
       "workingday    0.002209 -0.247877    1.000000  0.036898      0.057356   \n",
       "weekday      -0.003679 -0.094536    0.036898  1.000000      0.000816   \n",
       "weather_type -0.029682 -0.013434    0.057356  0.000816      1.000000   \n",
       "temp          0.131916 -0.008131    0.053103  0.000837     -0.083150   \n",
       "humidity     -0.271771  0.006655    0.025730 -0.043147      0.417010   \n",
       "wind_speed    0.127540 -0.019608   -0.004804  0.025951      0.044447   \n",
       "casual        0.028011  0.002130   -0.015372 -0.000206     -0.015864   \n",
       "subscribed    0.371302 -0.041417    0.134013  0.015390     -0.131915   \n",
       "usage         0.098023 -0.005842    0.010684  0.002738     -0.040555   \n",
       "\n",
       "                  temp  humidity  wind_speed    casual  subscribed     usage  \n",
       "hour          0.131916 -0.271771    0.127540  0.028011    0.371302  0.098023  \n",
       "holiday      -0.008131  0.006655   -0.019608  0.002130   -0.041417 -0.005842  \n",
       "workingday    0.053103  0.025730   -0.004804 -0.015372    0.134013  0.010684  \n",
       "weekday       0.000837 -0.043147    0.025951 -0.000206    0.015390  0.002738  \n",
       "weather_type -0.083150  0.417010    0.044447 -0.015864   -0.131915 -0.040555  \n",
       "temp          1.000000 -0.032506   -0.035742  0.040763    0.332923  0.103055  \n",
       "humidity     -0.032506  1.000000   -0.282958 -0.036357   -0.268173 -0.086425  \n",
       "wind_speed   -0.035742 -0.282958    1.000000  0.010544    0.080219  0.025531  \n",
       "casual        0.040763 -0.036357    0.010544  1.000000    0.065853  0.981693  \n",
       "subscribed    0.332923 -0.268173    0.080219  0.065853    1.000000  0.254705  \n",
       "usage         0.103055 -0.086425    0.025531  0.981693    0.254705  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 13084 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08f8c53978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(data.hour, data.subscribed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 13084 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGRqSpM7+PyI/+s67PlS5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08f8c53780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(data.hour, data.casual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timur/dev_ides/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for subscribed:  147.649618561\n",
      "R2:  0.765351766326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "data_test_set = data\n",
    "\n",
    "data_test_set = data_test_set.drop(['date', 'casual', 'subscribed', 'usage'], 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_test_set, data[['casual', 'subscribed']])\n",
    "\n",
    "# X_train = np.transpose(np.atleast_2d(X_train))\n",
    "# X_test = np.transpose(np.atleast_2d(X_test))\n",
    "\n",
    "y_train_subsribed = y_train.subscribed\n",
    "y_test_subscribed = y_test.subscribed\n",
    "\n",
    "linear_regression1 = GradientBoostingRegressor()\n",
    "\n",
    "linear_regression1.fit(X_train, y_train_subsribed)\n",
    "y_predicted1 = linear_regression1.predict(X_test)\n",
    "print(\"Error for subscribed: \", mean_absolute_error(y_test_subscribed, y_predicted1))\n",
    "print(\"R2: \", r2_score(y_test_subscribed, y_predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for casual:  153.426984466\n",
      "R2:  0.00432891942426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "data_test_set = data\n",
    "\n",
    "data_test_set = data_test_set.drop(['date', 'casual', 'subscribed', 'usage'], 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_test_set, data[['casual', 'subscribed']])\n",
    "\n",
    "# X_train = np.transpose(np.atleast_2d(X_train))\n",
    "# X_test = np.transpose(np.atleast_2d(X_test))\n",
    "\n",
    "y_train_casual = y_train.casual\n",
    "y_test_casual = y_test.casual\n",
    "\n",
    "linear_regression2 = LinearRegression()\n",
    "\n",
    "linear_regression2.fit(X_train, y_train_casual)\n",
    "y_predicted2 = linear_regression2.predict(X_test)\n",
    "print(\"Error for casual: \", mean_absolute_error(y_test_casual, y_predicted2))\n",
    "print(\"R2: \", r2_score(y_test_casual, y_predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timur/dev_ides/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py:2482: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d9ac033758cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_predicted1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_predicted2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_casual\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/timur/dev_ides/anaconda3/lib/python3.5/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \"\"\"\n\u001b[0;32m    162\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 163\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    164\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n\u001b[0;32m    165\u001b[0m                                weights=sample_weight, axis=0)\n",
      "\u001b[1;32m/home/timur/dev_ides/anaconda3/lib/python3.5/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m     74\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/timur/dev_ides/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/timur/dev_ides/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 58\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "y_final = y_predicted1 + y_predicted2\n",
    "mean_absolute_error(y_test_casual + y_test, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "data_test_set = data\n",
    "\n",
    "data_test_set = data_test_set.drop(['date', 'holiday', 'weekday', 'ftemp', 'casual', 'subscribed', 'usage'], 1)\n",
    "X_train, X_test, y_train, y_test = btrain_test_split(data_test_set, data.subscribed)\n",
    "\n",
    "# X_train = np.transpose(np.atleast_2d(X_train))\n",
    "# X_test = np.transpose(np.atleast_2d(X_test))\n",
    "\n",
    "errors = []\n",
    "for i in range(1, 100, 1):\n",
    "    linear_regression1 = KNeighborsRegressor(n_neighbors=i, n_jobs=-1)\n",
    "\n",
    "    linear_regression1.fit(X_train, y_train)\n",
    "    y_predicted1 = linear_regression1.predict(X_test)\n",
    "#     print(\"Error for subscribed: \", mean_absolute_error(y_test, y_predicted1))\n",
    "#     print(\"R2: \", r2_score(y_test, y_predicted1))\n",
    "    errors.append(mean_absolute_error(y_test, y_predicted1))\n",
    "min(errors)\n",
    "errors.index(min(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for casual:  120.675893052\n",
      "R2:  -86.0408378046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "data_test_set = data\n",
    "\n",
    "data_test_set = data_test_set.drop(['date', 'holiday', 'weekday', 'ftemp', 'casual', 'subscribed', 'usage'], 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_test_set, data.casual)\n",
    "\n",
    "# X_train = np.transpose(np.atleast_2d(X_train))\n",
    "# X_test = np.transpose(np.atleast_2d(X_test))\n",
    "\n",
    "# linear_regression2 = KNeighborsRegressor(n_neighbors=1, n_jobs=-1)\n",
    "linear_regression2 = RandomForestRegressor(n_estimators=100, max_features ='sqrt')\n",
    "\n",
    "linear_regression2.fit(X_train, y_train)\n",
    "y_predicted2 = linear_regression2.predict(X_test)\n",
    "print(\"Error for casual: \", mean_absolute_error(y_test, y_predicted2))\n",
    "print(\"R2: \", r2_score(y_test, y_predicted2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
